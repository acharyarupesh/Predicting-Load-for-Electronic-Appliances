{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\importlib\\_bootstrap_external.py:426: ImportWarning: Not importing directory C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\importlib\\_bootstrap_external.py:426: ImportWarning: Not importing directory c:\\users\\achar\\anaconda3\\lib\\site-packages\\mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n",
      "C:\\Users\\achar\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sklearn\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('energydata_Transformation.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekType = pd.get_dummies(data['weekType'], prefix = 'weekType')\n",
    "day_of_week = pd.get_dummies(data['day_of_week'], prefix = 'day_of_week')\n",
    "#['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "#['Weekend', 'Weekday']\n",
    "\n",
    "# Concat above dummies variable dataframe to the main dataframe\n",
    "data = pd.concat((data,weekType),axis=1)\n",
    "data = pd.concat((data,day_of_week),axis=1)\n",
    "\n",
    "# Drop the WeekStatus and Day_of_week column\n",
    "data = data.drop(['weekType','day_of_week','date', 'time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_outliers = ['Appliances', 'temp_kitchen', 'hum_kitchen', 'temp_living',\n",
    "       'hum_living', 'temp_laundry', 'hum_laundry', 'temp_office',\n",
    "       'hum_office', 'temp_bathroom', 'hum_bathroom', 'temp_building_out',\n",
    "       'hum_building_out', 'temp_ironing', 'hum_ironing', 'temp_teenRoom',\n",
    "       'hum_teenRoom', 'hum_parentRoom', 'Pressure', 'hum_out', 'Windspeed',\n",
    "       'Visibility', 'Tdewpoint', 'rv1']\n",
    "\n",
    "for x in data[check_outliers]:\n",
    "    data = data[np.abs(data[x]-data[x].mean()) <= (3*data[x].std())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test = train_test_split(data,train_size=0.7,random_state=42)\n",
    "x_train=data_train.iloc[:,1:]\n",
    "y_train=data_train['Appliances']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=data_test.iloc[:,1:]\n",
    "y_test=data_test['Appliances']\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achar\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -2351.5466157697742\n",
      "Generation 2 - Current best internal CV score: -2351.5466157697742\n",
      "Generation 3 - Current best internal CV score: -2351.5466157697742\n",
      "Generation 4 - Current best internal CV score: -2351.5466157697742\n",
      "Generation 5 - Current best internal CV score: -2301.0843441249162\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), bootstrap=False, max_features=0.15000000000000002, min_samples_leaf=5, min_samples_split=6, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "       disable_update_check=False, early_stop=None, generations=5,\n",
       "       max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "       mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "       periodic_checkpoint_folder=None, population_size=20,\n",
       "       random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "       verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tpot = TPOTRegressor(generations=5, population_size = 20 , verbosity= 2)  \n",
    "my_tpot.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-900.2838463288963\n"
     ]
    }
   ],
   "source": [
    "print(my_tpot.score(x_train_sc, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2394.4671160521625\n"
     ]
    }
   ],
   "source": [
    "print(my_tpot.score(x_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
